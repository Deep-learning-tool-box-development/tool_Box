#关于核函数</br>
linear 因特征线性可分不明显，训练太慢，舍去。</br>

|错误率(运行时间)   | 1e3                 |1e2            |1e1              |1              |1e-1         |1e-2        |1e-3        |1e-4     |1e-5|
| :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: |:----: |
|**rbf**    | 0.090(192s)      | 0.090(191s)   | 0.089(202s)    | 0.113(170s) | 0.372(180s)|0.598(213s)|0.598(228s)|0.598()|0.598()|
| **poly**  | 0.443(307s)      |0.433(308s)    | 0.413(279s)    | 0.454(249s) | 0.514(236s)|0.596(229s)|0.598(206s)|0.598()|0.598()|
| **sigmoid** | 0.789(156s)     |0.764(162s)    | 0.751(174s)    | 0.680(206s) |0.599(218s)|0.598(226s)|0.598()     |0.598()|0.598()|

由于数据的属性，本次数据集值适用于核函数 rbf</br>
当 C<1 时，正确率明显下降</br>
最优取值为 C=[1000,100], Kernel = ["rbf"]</br>

#以下为笔记
SVM模型有两个非常重要的参数C与gamma。</br>

其中 C是惩罚系数，即对误差的宽容度。c越高，说明越不能容忍出现误差,容易过拟合。C越小，容易欠拟合。C过大或过小，泛化能力变差。C一般可以选择为：10^t , t=[- 4，4]就是0.0001 到10000。</br>

gamma是选择RBF函数作为kernel后，该函数自带的一个参数。隐含地决定了数据映射到新的特征空间后的分布，gamma越大，支持向量越少，gamma值越小，支持向量越多。支持向量的个数影响训练与预测的速度。</br>

Grid Search </br>
使用grid Search虽然比较简单，而且看起来很naïve。但是他确实有两个优点： </br>
可以得到全局最优 </br>
(C,gamma)相互独立，便于并行化进行</br>
https://blog.csdn.net/ztf312/article/details/98594359
